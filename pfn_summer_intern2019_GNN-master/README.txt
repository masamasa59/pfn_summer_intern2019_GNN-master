
ソースコードのビルド方法・実行手順について
jupyter notebook上でセルの上から順番に実行する.
___________________________________________________________________________________________________________

課題１：グラフの集約を行い、特徴量を作成.

        ー関数の説明ー
        関数model() に引数として, data_x: 特徴量（ノード数，　次元数）の行列, G: 隣接行列で表したグラフ, W:　GNNのパラメータ,
        を入力すると返り値がグラフの特徴量.
        
        ー関数の内部処理ー
        グラフの各頂点ごとに隣接する頂点番号をset_idに格納。
        i回目の集約は各ノードごとに隣接するノードの値を総和し，aiに格納。
        aiとWの内積をとり、reLu関数で活性化したのちfiに格納。
        T回集約したあと、fTの総和をとり、hに格納。　
        
        ー設定ー
        今回はT = ３. ノードの特徴量の初期化は２次元で[0,1]ベクトル. ノードの総数は４. エッジはnotebookの隣接行列参照.　
        
        ー実行手順ー
        model()にdata_x,　G,　Wを与えると, グラフの特徴量が返る.
        
        ーテストについてー
        テストを今まで書いたことがなく、調べたが、どう書けばいいか曖昧な理解で、とりあえず、自分の手元で得られた結果と同じ挙動ができることをテストコードとした.
        
       
___________________________________________________________________________________________________________

課題２：あるグラフに対してラベルを{0,1}で設定し，　学習することでバイナリ交差エントロピーが減少することを確認.

        ー関数の説明ー
        関数model2(data_x, G, W, A, b, y)の引数に先ほどのdata_x,　G,　Wと特徴量にかける線形パラメータA　とバイアスパラメータb，　グラフのラベルy を与えると，
        出力に損失関数のバイナリ交差エントロピーが出力される.
        関数gradient(data_x, G, W, A, b, y)に同じものを与えると，　パラメータ{W,A,b}をepoch数分, model2()を用いて数値微分をし、パラメータを更新する。
        さらに、その時の交差エントロピーの値をリストに格納し関数gradient()の返り値でリストを返す.

        ー関数gradient()の内部処理ー
        各パラメータを数値微分するために、マスク代わりのデルタ関数の役割の行列を作成.　その行列は微分をとるパラメータのみεを足して、他の要素は０の行列。
        微分計算をする度に、そのパラメータに対してεを足して、他の要素を０にする.
        その後に数値微分の計算し、その勾配を用いてパラメータを更新。
        
        ー設定ー
        iteration = 5000 繰り返し, epsilon =0.001　数値微分時のδ幅 , alpha = 0.01 学習率　, 
        G グラフ　ノード数１０、エッジはnotebookの隣接行列参照.　ノードの次元は２で[0,1]ベクトルで統一.
        パラメータの初期化はヒントを参考.
        
        ー実行手順ー
        gradient()にdata_x, G, W, A, b, yを与えると, 5000回パラメータ更新したときの損失関数値のリストが返る.
 
         ーテストについてー
         自分の手元で得られた結果と同じ挙動ができることをテストコードとした.
        　　こちらが設定したグラフとノードに対してラベルが1,0両方でも、損失が0.03以下になることを示した.
       

___________________________________________________________________________________________________________


課題３:dataを読み込み、SGDとmomentum SGDをそれぞれ実装し，　訓練データと評価データで、平均精度と平均損失を各エポックごとに計算し、プロット。

        ー関数の説明ー
        model2()に追加でtestの変数を追加。Test=Trueは評価データを使う場合、Falseは訓練データを使う場合で最後の返り値が異なる。
        
        ー関数の内部処理ー
        test =Trueの時、つまり評価時は損失関数の値を返すのではなく、正しく予測できているか1,0で返す。１なら不正解. 0なら正解.
        最終的にmodel2()に評価データ全てを入力し、その総和が小さいほど正答率が高いことになる.

        ー設定ー
        共通部分
        epoch = 20, mini Batch =125,  epsilon =0.001　数値微分時のδ幅 , ノードの初期特徴量は8で[1,0,0,0,0,0,0,0]ベクトルで統一.
        パラメータの初期化はヒントを参考.　学習データ1500, 評価500
        SGDの場合
        alpha = 0.01 学習率. 
        MomentumSGDの場合
        alpha = 0.001 学習率, eta =0.9 mormentum率
        
        ー実行手順ー
        [2]model2()を用意.
        [3]データを'datasets/train/'からグラフとグラフの次元から作った初期化特徴量、ラベルをそれぞれtrain_graph, train_value, train_labelのリストに読み込む.
            評価データはtest_graph, test_value,test_label に読み込む.
        [4]SGDの実装　各エポックごとに訓練データと評価データで、平均精度と平均損失を計算し、
            それぞれリストtraining_loss ,training_fault ,validation_loss, validation_faultに格納.
        [5]それぞれリストをプロット
        [6]Momentum SGDの実装　各エポックごとに訓練データと評価データで、平均精度と平均損失を計算し、
            それぞれリストtraining_loss ,training_fault ,validation_loss, validation_faultに格納.
        [7]それぞれリストをプロット


___________________________________________________________________________________________________________
        
課題4：Adamで実装し、テストデータに対する予測ラベルをprediction.txtに書き出し.
        SGDにあたる処理をAdamに書き換え.
        
         ー関数の説明ー
        model2()に引数がtest=2の時、予測値を返すように書き換えた.
        
        ー設定ー
        共通部分
        epoch = 20, mini Batch =125,  epsilon =0.001　数値微分時のδ幅 , ノードの初期特徴量は8で[1,0,0,0,0,0,0,0]ベクトルで統一.
        パラメータの初期化はヒントを参考.  学習データ1500, 評価500
        Adamの設定　論文内のアルゴリズムの初期値参照.
        alpha= 0.001　学習率、p1 = 0.9　減衰率、p2 = 0.999　減衰率、e = 10e-8　
        
        ー実行手順ー
        [2]model2()を用意.
        [3]データを'datasets/train/'からグラフとグラフの次元から作った初期化特徴量、ラベルをそれぞれtrain_graph, train_value, train_labelのリストに読み込む.
            評価データはtest_graph, test_value,test_label に読み込む.
        [4]Adamの実装　各エポックごとに訓練データと評価データで、平均精度と平均損失を計算し,
            それぞれリストtraining_loss ,training_fault ,validation_loss, validation_faultに格納.
        [5]それぞれリストをプロット 
	[6]データを'datasets/test/'からグラフとグラフの次元から作った初期化特徴量をそれぞれtest_graph, test_valueのリストに読み込む.
        [7]prediction.txtにmodel2()を介して予測値を書き出し.
